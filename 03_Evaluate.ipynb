{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we evaluate the accuracy of the predicted alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_ROOT = Path('Chopin_Mazurkas/annotations_beat')\n",
    "query_list = Path('cfg_files/query.test.list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate hypothesis directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First evaluate a single hypothesis directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dir(hypdir, querylist, hop_sec, savefile = None):\n",
    "    \n",
    "    allErrs = {}\n",
    "    cnt = 0\n",
    "    print(f'Processing {hypdir} ', end='')\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            assert len(parts) == 2\n",
    "            basename = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            hypfile = hypdir + '/' + basename + '.pkl'\n",
    "            if not os.path.exists(hypfile):\n",
    "                print(\"X\", end='')\n",
    "                continue\n",
    "            allErrs[basename] = eval_file(hypfile, hop_sec)\n",
    "            cnt += 1\n",
    "            if cnt % 500 == 0:\n",
    "                print(\".\", end='')\n",
    "    print(' done')\n",
    "    if savefile:\n",
    "        pickle.dump(allErrs, open(savefile, 'wb'))\n",
    "        \n",
    "    return allErrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_file(hypfile, hop_sec):\n",
    "    parts = os.path.basename(hypfile).split('__')\n",
    "    assert len(parts) == 2\n",
    "    piece = extractPieceName(parts[0])\n",
    "    annotfile1 = (ANNOTATIONS_ROOT / piece / parts[0]).with_suffix('.beat')\n",
    "    annotfile2 = (ANNOTATIONS_ROOT / piece / parts[1]).with_suffix('.beat')\n",
    "    gt1 = getTimestamps(annotfile1)\n",
    "    gt2 = getTimestamps(annotfile2)\n",
    "    hypalign = loadAlignment(hypfile) # warping path in frames\n",
    "    if hypalign is None:\n",
    "        err = [] # no valid path\n",
    "    else:\n",
    "        pred2 = np.interp(gt1, hypalign[0,:]*hop_sec, hypalign[1,:]*hop_sec)\n",
    "        err = pred2 - gt2\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPieceName(fullpath):\n",
    "    basename = os.path.basename(fullpath) # e.g. Chopin_Op068No3_Sztompka-1959_pid9170b-21\n",
    "    parts = basename.split('_')\n",
    "    piece = '_'.join(parts[0:2]) # e.g. Chopin_Op068No3\n",
    "    return piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestamps(annotfile):\n",
    "    df = pd.read_csv(annotfile, header=None, sep='\\s+', skiprows=3)\n",
    "    return np.array(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAlignment(hypfile):\n",
    "    with open(hypfile, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate a single hypothesis directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypdir = 'experiments_test/ssdtw_2_clean'\n",
    "savefile = 'evaluations_test/ssdtw_2_clean.pkl'\n",
    "hop_sec = 512 * 1 / 22050\n",
    "allErrs = eval_dir(hypdir, query_list, hop_sec, savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all hypothesis directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_dirs(rootdir, querylist, hop_sec, outdir):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    for hypdir in glob.glob(f'{rootdir}/ssdtw_*'):\n",
    "        savefile = outdir + '/' + os.path.basename(hypdir) + '.pkl'\n",
    "        allErrs = eval_dir(hypdir, querylist, hop_sec, savefile = savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_ROOT = 'experiments_test'\n",
    "hop_sec = 512 * 1 / 22050\n",
    "outdir = 'evaluations_test'\n",
    "eval_all_dirs(EXPERIMENTS_ROOT, query_list, hop_sec, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot error vs tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_rates(errFile, maxTol):\n",
    "    \n",
    "    # read from file\n",
    "    with open(errFile, 'rb') as f:\n",
    "        allErrs = pickle.load(f)\n",
    "    \n",
    "    # collect all errors\n",
    "    errsFlat = []\n",
    "    for query in allErrs:\n",
    "        errs = np.array(allErrs[query])\n",
    "        errsFlat.append(errs)\n",
    "    errsFlat = np.concatenate(errsFlat)\n",
    "    \n",
    "    # calculate error rates\n",
    "    errRates = np.zeros(maxTol+1)\n",
    "    for i in range(maxTol+1):\n",
    "        errRates[i] = np.mean(np.abs(errsFlat) > i/1000)\n",
    "    \n",
    "    return errRates, errsFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error_rates_batch(indir, basenames, maxTol):\n",
    "    errRates = np.zeros((len(basenames), maxTol+1))\n",
    "    allErrVals = []\n",
    "    print('Computing error rates ', end='')\n",
    "    for i, basename in enumerate(basenames):\n",
    "        errFile = indir + '/' + basename + '.pkl'\n",
    "        errRates[i,:], errors = calc_error_rates(errFile, maxTol)\n",
    "        allErrVals.append(errors)\n",
    "        print('.', end='')\n",
    "    print(' done')\n",
    "    return errRates, allErrVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_roc(errRates, basenames):\n",
    "    numSystems = errRates.shape[0]\n",
    "    maxTol = errRates.shape[1] - 1\n",
    "    for i in range(numSystems):\n",
    "        plt.plot(np.arange(maxTol+1), errRates[i,:] * 100.0)\n",
    "    plt.legend(basenames, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel('Error Tolerance (ms)')\n",
    "    plt.ylabel('Error Rate (%)')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_ROOT_DIR = 'evaluations_test'\n",
    "toPlot = ['dtw_clean', 'segmental_2_clean', 'segmental_4_clean', 'segmental_8_clean', 'segmental_16_clean', 'segmental_32_clean', 'pardtw_2_clean', 'pardtw_4_clean', 'pardtw_8_clean', 'pardtw_16_clean', 'pardtw_32_clean']\n",
    "maxTol = 1000 # in msec\n",
    "errRates, errVals = calc_error_rates_batch(EVAL_ROOT_DIR, toPlot, maxTol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_roc(errRates, toPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of selected error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_histogram1(errRates, basenames, tols):  \n",
    "    # Histogram grouped by tolerance\n",
    "    \n",
    "    # first construct DataFrame\n",
    "    data = []\n",
    "    for i, system in enumerate(basenames):\n",
    "        for tol in tols:\n",
    "            data.append((system, tol, errRates[i,tol] * 100.0))\n",
    "    df = pd.DataFrame(data, columns = ['System', 'Tolerance', 'Error'])\n",
    "    \n",
    "    # grouped barplot\n",
    "    sns.barplot(x=\"Tolerance\", y=\"Error\", hue=\"System\", data=df)\n",
    "    plt.xlabel(\"Tolerance (ms)\", size=14)\n",
    "    plt.ylabel(\"Error Rate\", size=14)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = [10, 20, 50, 100, 200, 500] # in msec\n",
    "plot_grouped_histogram1(errRates, toPlot, tols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results plot for paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is touched up to look nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_histogram1(errRates_bars, errRates_dots, basenames, tols, savefile = None):  \n",
    "    # Histogram grouped by tolerance\n",
    "    \n",
    "    # first construct DataFrame\n",
    "    data = []\n",
    "    for i, system in enumerate(basenames):\n",
    "        for tol in tols:\n",
    "            data.append((system, tol, errRates[i,tol] * 100.0))\n",
    "    df = pd.DataFrame(data, columns = ['System', 'Tolerance', 'Error'])\n",
    "    \n",
    "    # grouped barplot (DTW & WSDTW)\n",
    "    sns.barplot(x=\"Tolerance\", y=\"Error\", hue=\"System\", data=df)\n",
    "    plt.xlabel(\"Tolerance (ms)\", size=14)\n",
    "    plt.ylabel(\"Error Rate (%)\", size=14)\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # overlay dots for SSDTW results\n",
    "    width_bar = .135\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "    for i, tol in enumerate(tols):\n",
    "        for j in range(errRates_dots.shape[0]):\n",
    "            x_coords.append(i+(-1.5+j)*width_bar)\n",
    "            y_coords.append(errRates_dots[j,tol] * 100.0)\n",
    "    plt.plot(x_coords, y_coords, 'ko', markersize=3)\n",
    "    \n",
    "    if savefile:\n",
    "        plt.savefig(savefile, bbox_inches = 'tight')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = [10, 20, 50, 100, 200, 500] # in msec\n",
    "display_names = ['DTW', 'SegDTW-2', 'SegDTW-4', 'SegDTW-8', 'SegDTW-16','SegDTW-32']\n",
    "savefile = 'results.png'\n",
    "plot_grouped_histogram1(errRates[0:6,:], errRates[6:,:], display_names, tols, savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_runtimes, dtw_sizes = pickle.load(open('dtw_prof.pkl', 'rb'))\n",
    "# wsdtw_runtimes, wsdtw_segments, wsdtw_sizes = pickle.load(open('wsdtw_prof.pkl', 'rb'))\n",
    "# ssdtw_runtimes, ssdtw_segments, ssdtw_sizes = pickle.load(open('ssdtw_prof.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers for runtime table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_avgs = np.mean(np.sum(dtw_runtimes[::-1,:,:], axis=2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wsdtw_avgs = np.mean(np.sum(wsdtw_runtimes[:,::-1,:,:], axis=3), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssdtw_avgs = np.mean(np.sum(ssdtw_runtimes[:,::-1,:,:], axis=3), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_avgs = np.vstack((dtw_avgs.reshape((1,-1)), wsdtw_avgs, ssdtw_avgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row: DTW\n",
    "# next 5 rows: WSDTW with segments = 2, 4, 8, 16, 32\n",
    "# next 5 rows: SSDTW with segments = 2, 4, 8, 16, 32\n",
    "dtw_avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown of runtime by component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DTW percent of total runtime by component\n",
    "dtw_avgs = np.mean(dtw_runtimes, axis=1)\n",
    "dtw_avgs = dtw_avgs / np.sum(dtw_avgs, axis=1, keepdims=True) * 100.0\n",
    "dtw_avgs = dtw_avgs[::-1,:]\n",
    "dtw_avgs = np.hstack((dtw_avgs, np.zeros((6,2)))) # order: cost, frm dp, frm back, seg dp, seg back\n",
    "dtw_df = pd.DataFrame(dtw_avgs, columns=['Cost', 'Frm DP', 'Frm Back','Seg DP', 'Seg Back'], index=dtw_sizes[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get WSDTW percent of total runtime by component\n",
    "# wsdtw_avgs = np.mean(wsdtw_runtimes, axis=2)\n",
    "# wsdtw_avgs = wsdtw_avgs / np.sum(wsdtw_avgs, axis=2, keepdims=True) * 100.0\n",
    "# wsdtw_avgs = wsdtw_avgs[4,::-1,:] # focus on K=32 segments\n",
    "# wsdtw_avgs = wsdtw_avgs[:,[0,1,4,2,3]] # original order: cost, frm dp, seg dp, seg back, frm back\n",
    "# wsdtw_df = pd.DataFrame(wsdtw_avgs, columns=['Cost', 'Frm DP', 'Frm Back','Seg DP', 'Seg Back'], index=wsdtw_sizes[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get SSDTW percent of total runtime by component\n",
    "# ssdtw_avgs = np.mean(ssdtw_runtimes, axis=2)\n",
    "# ssdtw_avgs = ssdtw_avgs / np.sum(ssdtw_avgs, axis=2, keepdims=True) * 100.0\n",
    "# ssdtw_avgs = ssdtw_avgs[4,::-1,:] # focus on K=32 segments\n",
    "# ssdtw_avgs[:,2] = ssdtw_avgs[:,2] + ssdtw_avgs[:,5] # combine runtimes from both frame-level backtracking stages\n",
    "# ssdtw_avgs = ssdtw_avgs[:,0:5] # order: cost, frm dp, frm back, seg dp, seg back\n",
    "# ssdtw_df = pd.DataFrame(ssdtw_avgs, columns=['Cost', 'Frm DP', 'Frm Back','Seg DP', 'Seg Back'], index=ssdtw_sizes[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "# DTW plot\n",
    "ax = dtw_df.plot(kind=\"bar\", stacked=True, colormap=\"rainbow\", ax=axes[0])\n",
    "ax.set_title(\"DTW\")\n",
    "ax.set_ylabel(\"% Total Runtime\", size=13),\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 10))\n",
    "ax.xaxis.set_ticks_position('none') \n",
    "ax.set_xticklabels(labels=['1k','2k','5k','10k','20k','50k'], rotation=90, minor=False)\n",
    "ax.get_legend().remove()\n",
    "\n",
    "# # Segmental DTW plot\n",
    "# ax = wsdtw_df.plot(kind=\"bar\", stacked=True, colormap=\"rainbow\", ax=axes[1])\n",
    "# ax.set_title(\"WSDTW-32\")\n",
    "# ax.set_xlabel(\"\\nCost Matrix Size\", size=13),\n",
    "# ax.set_ylim(0, 100)\n",
    "# ax.set_yticks([])\n",
    "# ax.xaxis.set_ticks_position('none') \n",
    "# ax.set_xticklabels(labels=['1k','2k','5k','10k','20k','50k'], rotation=90, minor=False)\n",
    "# ax.get_legend().remove()\n",
    "\n",
    "# # Par DTW plot\n",
    "# ax = ssdtw_df.plot(kind=\"bar\", stacked=True, colormap=\"rainbow\", ax=axes[2])\n",
    "# ax.set_title(\"SSDTW-32\")\n",
    "# ax.set_ylim(0, 100)\n",
    "# ax.set_yticks([])\n",
    "# ax.xaxis.set_ticks_position('none') \n",
    "# ax.set_xticklabels(labels=['1k','2k','5k','10k','20k','50k'], rotation=90, minor=False)\n",
    "\n",
    "# ax.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('runtime.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Stats for paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting some stats on the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Chopin_Mazurkas/wav_22050_mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAudioStats(indir):\n",
    "    durs = []\n",
    "    for infile in glob.glob(f'{indir}/*.wav'):\n",
    "        y, sr = lb.load(infile)\n",
    "        durs.append(len(y)/sr)\n",
    "    durs = np.array(durs)\n",
    "    \n",
    "    print(os.path.basename(indir))\n",
    "    print('---------')\n",
    "    print(f'Min: {np.min(durs)} s')\n",
    "    print(f'Max: {np.max(durs)} s')\n",
    "    print(f'Mean: {np.mean(durs)} s')\n",
    "    print(f'Std: {np.std(durs)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indir in glob.glob(f'{root_dir}/*'):\n",
    "    printAudioStats(indir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DropDTW",
   "language": "python",
   "name": "dropdtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
