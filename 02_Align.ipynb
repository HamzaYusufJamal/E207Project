{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to align files using DTW, weakly-ordered Segmental DTW, or strictly-ordered Segmental DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lb\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align with DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a cython implementation of basic DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "DTYPE_INT32 = np.int32\n",
    "ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "DTYPE_FLOAT = np.float64\n",
    "ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_Cost_To_AccumCostAndSteps(Cin, parameter):\n",
    "    '''\n",
    "    Inputs\n",
    "        C: The cost Matrix\n",
    "    '''\n",
    "\n",
    "\n",
    "    '''\n",
    "    Section for checking and catching errors in the inputs\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] C\n",
    "    try:\n",
    "        C = np.array(Cin, dtype=DTYPE_FLOAT)\n",
    "    except TypeError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the cost matrix is wrong - please pass in a 2-d numpy array\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "    except ValueError:\n",
    "        print(bcolors.FAIL + \"FAILURE: The type of the elements in the cost matrix is wrong - please have each element be a float (perhaps you passed in a matrix of ints?)\" + bcolors.ENDC)\n",
    "        return [-1, -1, -1]\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dn\n",
    "    cdef np.ndarray[np.uint32_t, ndim=1] dm\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=1] dw\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    # dn loading and exception handling\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        try:\n",
    "\n",
    "            dn = np.array(parameter['dn'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dn (row steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"The type of the elements in dn (row steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=np.uint32)\n",
    "    # dm loading and exception handling\n",
    "    if 'dm'  in parameter.keys():\n",
    "        try:\n",
    "            dm = np.array(parameter['dm'], dtype=np.uint32)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dm (col steps) is wrong - please pass in a 1-d numpy array that holds uint32s\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of the elements in dm (col steps) is wrong - please have each element be a uint32 (perhaps you passed a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.uint32)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        print(bcolors.FAIL + \"dm (col steps) was not passed in (gave default value [1,0,1]) \" + bcolors.ENDC)\n",
    "        dm = np.array([1, 0, 1], dtype=np.uint32)\n",
    "    # dw loading and exception handling\n",
    "    if 'dw'  in parameter.keys():\n",
    "        try:\n",
    "            dw = np.array(parameter['dw'], dtype=DTYPE_FLOAT)\n",
    "        except TypeError:\n",
    "            print(bcolors.FAIL + \"FAILURE: The type of dw (step weights) is wrong - please pass in a 1-d numpy array that holds floats\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "        except ValueError:\n",
    "            print(bcolors.FAIL + \"FAILURE:The type of the elements in dw (step weights) is wrong - please have each element be a float (perhaps you passed ints or a long?). You can specify this when making a numpy array like: np.array([1,2,3],dtype=np.float64)\" + bcolors.ENDC)\n",
    "            return [-1, -1, -1]\n",
    "    else:\n",
    "        dw = np.array([1, 1, 1], dtype=DTYPE_FLOAT)\n",
    "        print(bcolors.FAIL + \"dw (step weights) was not passed in (gave default value [1,1,1]) \" + bcolors.ENDC)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Section where types are given to the variables we're going to use \n",
    "    '''\n",
    "    # create matrices to store our results (D and E)\n",
    "    cdef DTYPE_INT32_t numRows = C.shape[0] # only works with np arrays, use np.shape(x) will work on lists? want to force to use np though?\n",
    "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
    "    cdef DTYPE_INT32_t numDifSteps = np.size(dw)\n",
    "\n",
    "    cdef unsigned int maxRowStep = max(dn)\n",
    "    cdef unsigned int maxColStep = max(dm)\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] steps = np.zeros((numRows,numCols), dtype=np.uint32)\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((maxRowStep + numRows, maxColStep + numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "    cdef DTYPE_FLOAT_t bestCost\n",
    "    cdef DTYPE_INT32_t bestCostIndex\n",
    "    cdef DTYPE_FLOAT_t costForStep\n",
    "    cdef unsigned int row, col\n",
    "    cdef unsigned int stepIndex\n",
    "\n",
    "    '''\n",
    "    The start of the actual algorithm, now that all our variables are set up\n",
    "    '''\n",
    "    # initializing the cost matrix - depends on whether its subsequence DTW\n",
    "    # essentially allow us to hop on the bottom anywhere (so could start partway through one of the signals)\n",
    "    if parameter['SubSequence']:\n",
    "        for col in range(numCols):\n",
    "            accumCost[maxRowStep, col + maxColStep] = C[0, col]\n",
    "    else:\n",
    "        accumCost[maxRowStep, maxColStep] = C[0,0]\n",
    "\n",
    "    # filling the accumulated cost matrix\n",
    "    for row in range(maxRowStep, numRows + maxRowStep, 1):\n",
    "        for col in range(maxColStep, numCols + maxColStep, 1):\n",
    "            bestCost = accumCost[<unsigned int>row, <unsigned int>col] # initialize with what's there - so if is an entry point, then can start low\n",
    "            bestCostIndex = 0\n",
    "            # go through each step, find the best one\n",
    "            for stepIndex in range(numDifSteps):\n",
    "                #costForStep = accumCost[<unsigned int>(row - dn[<unsigned int>(stepIndex)]), <unsigned int>(col - dm[<unsigned int>(stepIndex)])] + dw[<unsigned int>(stepIndex)] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                costForStep = accumCost[<unsigned int>((row - dn[(stepIndex)])), <unsigned int>((col - dm[(stepIndex)]))] + dw[stepIndex] * C[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)]\n",
    "                if costForStep < bestCost:\n",
    "                    bestCost = costForStep\n",
    "                    bestCostIndex = stepIndex\n",
    "            # save the best cost and best cost index\n",
    "            accumCost[row, col] = bestCost\n",
    "            steps[<unsigned int>(row - maxRowStep), <unsigned int>(col - maxColStep)] = bestCostIndex\n",
    "\n",
    "    # return the accumulated cost along with the matrix of steps taken to achieve that cost\n",
    "    return [accumCost[maxRowStep:, maxColStep:], steps]\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "def DTW_GetPath(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
    "    '''\n",
    "\n",
    "    Parameter should have: 'dn', 'dm', 'dw', 'SubSequence'\n",
    "    '''\n",
    "\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dn\n",
    "    cdef np.ndarray[unsigned int, ndim=1] dm\n",
    "    cdef np.uint8_t subseq\n",
    "    cdef np.int32_t startCol # added\n",
    "    # make sure dn, dm, and dw are setup\n",
    "    if ('dn'  in parameter.keys()):\n",
    "        dn = parameter['dn']\n",
    "    else:\n",
    "        dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
    "    if 'dm'  in parameter.keys():\n",
    "        dm = parameter['dm']\n",
    "    else:\n",
    "        dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
    "    if 'SubSequence' in parameter.keys():\n",
    "        subseq = parameter['SubSequence']\n",
    "    else:\n",
    "        subseq = 0\n",
    "    \n",
    "    # added START\n",
    "    if 'startCol' in parameter.keys(): \n",
    "        startCol = parameter['startCol']\n",
    "    else:\n",
    "        startCol = -1\n",
    "    # added END\n",
    "\n",
    "    cdef np.uint32_t numRows\n",
    "    cdef np.uint32_t numCols\n",
    "    cdef np.uint32_t curRow\n",
    "    cdef np.uint32_t curCol\n",
    "    cdef np.uint32_t endCol\n",
    "    cdef DTYPE_FLOAT_t endCost\n",
    "\n",
    "    numRows = accumCost.shape[0]\n",
    "    numCols = accumCost.shape[1]\n",
    "\n",
    "    # either start at the far corner (non sub-sequence)\n",
    "    # or start at the lowest cost entry in the last row (sub-sequence)\n",
    "    # where all of the signal along the row has been used, but only a \n",
    "    # sub-sequence of the signal along the columns has to be used\n",
    "    curRow = numRows - 1\n",
    "    if subseq:\n",
    "        curCol = np.argmin(accumCost[numRows - 1, :])\n",
    "    else:\n",
    "        curCol = numCols - 1\n",
    "        \n",
    "    # added - if specified, overrides above\n",
    "    if startCol >= 0:\n",
    "        curCol = startCol\n",
    "\n",
    "    endCol = curCol\n",
    "    endCost = accumCost[curRow, curCol]\n",
    "\n",
    "    cdef np.uint32_t curRowStep\n",
    "    cdef np.uint32_t curColStep\n",
    "    cdef np.uint32_t curStepIndex\n",
    "\n",
    "\n",
    "    cdef np.ndarray[np.uint32_t, ndim=2] path = np.zeros((2, numRows + numCols), dtype=np.uint32) # make as large as could need, then chop at the end\n",
    "    path[0, 0] = curRow\n",
    "    path[1, 0] = curCol\n",
    "\n",
    "    cdef np.uint32_t stepsInPath = 1 # starts at one, we add in one before looping\n",
    "    cdef np.uint32_t stepIndex = 0\n",
    "    cdef np.int8_t done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "    while not done:\n",
    "        if accumCost[curRow, curCol] == MAX_FLOAT:\n",
    "            print('A path is not possible')\n",
    "            break\n",
    "\n",
    "        # you're done if you've made it to the bottom left (non sub-sequence)\n",
    "        # or just the bottom (sub-sequence)\n",
    "        # find the step size\n",
    "        curStepIndex = stepsForCost[curRow, curCol]\n",
    "        curRowStep = dn[curStepIndex]\n",
    "        curColStep = dm[curStepIndex]\n",
    "        # backtrack by 1 step\n",
    "        curRow = curRow - curRowStep\n",
    "        curCol = curCol - curColStep\n",
    "        # add your new location onto the path\n",
    "        path[0, stepsInPath] = curRow\n",
    "        path[1, stepsInPath] = curCol\n",
    "        stepsInPath = stepsInPath + 1\n",
    "        # check to see if you're done\n",
    "        done = (subseq and curRow == 0) or (curRow == 0 and curCol == 0)\n",
    "\n",
    "    # reverse the path (a matrix with two rows) and return it\n",
    "    return [np.fliplr(path[:, 0:stepsInPath]), endCol, endCost]\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignDTW(featfile1, featfile2, steps, weights, downsample, outfile = None, profile = False):\n",
    "    \n",
    "    F1 = np.load(featfile1) # 12 x N\n",
    "    F2 = np.load(featfile2) # 12 x M\n",
    "    if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "        if outfile:\n",
    "            pickle.dump(None, open(outfile, 'wb'))\n",
    "        return None\n",
    "    times = []\n",
    "    times.append(time.time())\n",
    "    C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "    times.append(time.time())\n",
    "\n",
    "    dn = steps[:,0].astype(np.uint32)\n",
    "    dm = steps[:,1].astype(np.uint32)\n",
    "    parameters = {'dn': dn, 'dm': dm, 'dw': weights, 'SubSequence': False}\n",
    "    [D, s] = DTW_Cost_To_AccumCostAndSteps(C, parameters)\n",
    "    times.append(time.time())\n",
    "    [wp, endCol, endCost] = DTW_GetPath(D, s, parameters)\n",
    "    times.append(time.time())\n",
    "    if outfile:\n",
    "        pickle.dump(wp, open(outfile, 'wb'))\n",
    "    \n",
    "    if profile:\n",
    "        return wp, np.diff(times)\n",
    "    else:\n",
    "        return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample):\n",
    "    \n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(querylist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            assert len(parts) == 2\n",
    "            featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "            featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "            queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            outfile = (outdir / queryid).with_suffix('.pkl')\n",
    "            if os.path.exists(outfile):\n",
    "                print(f\"Skipping {outfile}\")\n",
    "            else:\n",
    "                inputs.append((featfile1, featfile2, steps, weights, downsample, outfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(alignDTW, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align a single pair of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featfile1 = 'features/clean/Chopin_Op068No3/Chopin_Op068No3_Tomsic-1995_pid9190-11.npy'\n",
    "featfile2 = 'features/clean/Chopin_Op068No3/Chopin_Op068No3_Cortot-1951_pid9066b-19.npy'\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "wp = alignDTW(featfile1, featfile2, steps, weights, downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align all pairs of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = 'cfg_files/query.test.list'\n",
    "featdir1 = Path('features/clean')\n",
    "featdir2 = Path('features/clean') # in case you want to align clean vs noisy\n",
    "outdir = Path('experiments_test/dtw_clean')\n",
    "n_cores = 1\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "inputs = alignDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align with WSDTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align with weakly-ordered Segmental DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alignWSDTW(featfile1, featfile2, steps, weights, downsample, numSegments, outfile = None, profile = False):\n",
    "    \n",
    "#     # compute cost matrix\n",
    "#     F1 = np.load(featfile1) # 12 x N\n",
    "#     F2 = np.load(featfile2) # 12 x M\n",
    "#     if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "#         if outfile:\n",
    "#             pickle.dump(None, open(outfile, 'wb'))\n",
    "#         return None\n",
    "#     times = []\n",
    "#     times.append(time.time())\n",
    "#     C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "#     times.append(time.time())\n",
    "\n",
    "#     # run subseqDTW on chunks\n",
    "#     seglen = int(np.ceil(C.shape[0] / numSegments))\n",
    "#     dn1 = steps[:,0].astype(np.uint32)\n",
    "#     dm1 = steps[:,1].astype(np.uint32)\n",
    "#     dw1 = weights\n",
    "#     params1 = {'dn': dn1, 'dm': dm1, 'dw': dw1, 'SubSequence': True}\n",
    "#     Dparts = []\n",
    "#     Bparts = []\n",
    "#     for i in range(numSegments):\n",
    "#         Cpart = C[i*seglen : min((i+1)*seglen, C.shape[0]), :]\n",
    "#         [D, B] = DTW_Cost_To_AccumCostAndSteps(Cpart, params1)\n",
    "#         Dparts.append(D)\n",
    "#         Bparts.append(B)\n",
    "#     times.append(time.time())\n",
    "\n",
    "#     # run segment-level DP\n",
    "#     Cseg = np.zeros((numSegments+1, C.shape[1]))\n",
    "#     for i in range(len(Dparts)):\n",
    "#         Cseg[i+1,:] = Dparts[i][-1,:]\n",
    "#     dn2 = np.array([0, 1], dtype=np.uint32)\n",
    "#     dm2 = np.array([1, seglen//np.max(steps[:,0])], dtype=np.uint32)\n",
    "#     dw2 = np.array([0, 1])\n",
    "#     params2 = {'dn': dn2, 'dm': dm2, 'dw': dw2, 'SubSequence': False}\n",
    "#     [Dseg, Bseg] = DTW_Cost_To_AccumCostAndSteps(Cseg, params2)\n",
    "#     times.append(time.time())\n",
    "#     [wpseg, _, _] = DTW_GetPath(Dseg, Bseg, params2)\n",
    "\n",
    "#     # backtrace\n",
    "#     segmentEndIdxs = getSegmentEndingLocs(wpseg)\n",
    "#     times.append(time.time())\n",
    "#     wps = []\n",
    "#     for i, endidx in enumerate(segmentEndIdxs):\n",
    "#         params3 = {'dn': dn1, 'dm': dm1, 'dw': dw1, 'SubSequence': True, 'startCol': endidx}\n",
    "#         [wpchunk, _, _] = DTW_GetPath(Dparts[i], Bparts[i], params3)\n",
    "#         wpchunk[0,:] = wpchunk[0,:] + i*seglen  # account for relative offset\n",
    "#         wps.append(wpchunk.copy())\n",
    "#     wp_merged = np.hstack(wps)\n",
    "#     times.append(time.time())\n",
    "\n",
    "#     if outfile:\n",
    "#         pickle.dump(wp_merged, open(outfile, 'wb'))\n",
    "\n",
    "#     if profile:\n",
    "#         return wp_merged, np.diff(times)\n",
    "#     else:\n",
    "#         return wp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getSegmentEndingLocs(wp):\n",
    "#     prevLoc = wp[:,0] # [r,c]\n",
    "#     endLocs = []\n",
    "#     for i in range(wp.shape[1]):\n",
    "#         curLoc = wp[:,i]\n",
    "#         if curLoc[0] != prevLoc[0]: # if row changes\n",
    "#             endLocs.append(curLoc[1])\n",
    "#         prevLoc = curLoc\n",
    "        \n",
    "#     return endLocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alignSegmentalDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, numSegments, fn):\n",
    "\n",
    "#     outdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # prep inputs for parallelization\n",
    "#     inputs = []\n",
    "#     with open(querylist, 'r') as f:\n",
    "#         for line in f:\n",
    "#             parts = line.strip().split(' ')\n",
    "#             assert len(parts) == 2\n",
    "#             featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "#             featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "#             queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "#             outfile = (outdir / queryid).with_suffix('.pkl')\n",
    "#             if os.path.exists(outfile):\n",
    "#                 print(f\"Skipping {outfile}\")\n",
    "#             else:\n",
    "#                 inputs.append((featfile1, featfile2, steps, weights, downsample, numSegments, outfile))\n",
    "\n",
    "#     # process files in parallel\n",
    "#     pool = multiprocessing.Pool(processes = n_cores)\n",
    "#     pool.starmap(fn, inputs)\n",
    "\n",
    "#     return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align a single pair of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featfile1 = 'features/clean/Chopin_Op017No4/Chopin_Op017No4_Afanassiev-2001_pid9130-01.npy'\n",
    "# featfile2 = 'features/clean/Chopin_Op017No4/Chopin_Op017No4_Ben-Or-1989_pid9161-12.npy'\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# downsample = 1\n",
    "# numSegments = 5\n",
    "# # wp = alignWSDTW(featfile1, featfile2, steps, weights, downsample, numSegments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align all pairs of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_list = 'cfg_files/query.test.list'\n",
    "# featdir1 = Path('features/clean')\n",
    "# featdir2 = Path('features/clean') # in case you want to align clean vs noisy\n",
    "# n_cores = 1\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# downsample = 1\n",
    "# segmentVals = [2, 4, 8, 16, 32] \n",
    "# for numSegments in segmentVals:\n",
    "#     outdir = Path(f'experiments_test/wsdtw_{numSegments}_clean')\n",
    "#     alignSegmentalDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, numSegments, alignWSDTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align with SSDTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align with strictly-ordered Segmental DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cython\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# cimport cython\n",
    "\n",
    "# import sys\n",
    "# import time\n",
    "\n",
    "\n",
    "# DTYPE_INT32 = np.int32\n",
    "# ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "# DTYPE_FLOAT = np.float64\n",
    "# ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "# cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# # careful, without bounds checking can mess up memory - also can't use negative indices I think (like x[-1])\n",
    "# @cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "# def Segment_DP(np.ndarray[DTYPE_FLOAT_t, ndim=2] C, np.ndarray[np.int32_t, ndim=2] T):\n",
    "\n",
    "#     cdef DTYPE_INT32_t numRows = C.shape[0]\n",
    "#     cdef DTYPE_INT32_t numCols = C.shape[1]    \n",
    "#     cdef np.ndarray[np.int32_t, ndim=2] steps = np.zeros((numRows+1,numCols), dtype=np.int32)\n",
    "#     cdef np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost = np.ones((numRows+1, numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "#     cdef unsigned int row, col\n",
    "#     cdef DTYPE_FLOAT_t skipCost\n",
    "#     cdef np.int32_t jumpStartCol\n",
    "#     cdef DTYPE_FLOAT_t jumpCost\n",
    "\n",
    "#     # initialize\n",
    "#     for row in range(numRows+1):\n",
    "#         for col in range(numCols):\n",
    "#             steps[row, col] = -1 # skip by default\n",
    "#     for col in range(numCols):\n",
    "#         accumCost[0, col] = 0 # all inf except first row\n",
    "        \n",
    "#     # dynamic programming\n",
    "#     for row in range(1, numRows+1):\n",
    "#         for col in range(numCols):\n",
    "            \n",
    "#             # skip transition\n",
    "#             if col == 0:\n",
    "#                 skipCost = MAX_FLOAT\n",
    "#             else:\n",
    "#                 skipCost = accumCost[row, col-1]\n",
    "#             accumCost[row, col] = skipCost\n",
    "#             # best step is skip by default, so don't need to assign\n",
    "            \n",
    "#             # jump transition\n",
    "#             jumpStartCol = T[row-1, col]\n",
    "#             if jumpStartCol >= 0: # valid subsequence path\n",
    "#                 jumpCost = accumCost[row-1, jumpStartCol] + C[row-1, col]\n",
    "#                 if jumpCost < skipCost:\n",
    "#                     accumCost[row, col] = jumpCost\n",
    "#                     steps[row, col] = jumpStartCol\n",
    "\n",
    "#     return [accumCost, steps]\n",
    "\n",
    "# @cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "# def Segment_Backtrace(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.int32_t, ndim=2] steps):\n",
    "\n",
    "#     cdef np.uint32_t numRows = accumCost.shape[0]\n",
    "#     cdef np.uint32_t numCols = accumCost.shape[1]\n",
    "#     cdef np.uint32_t curRow = numRows - 1\n",
    "#     cdef np.uint32_t curCol = numCols - 1\n",
    "#     cdef np.int32_t jump\n",
    "#     cdef np.ndarray[np.uint32_t, ndim=1] path = np.zeros(numRows-1, dtype=np.uint32)\n",
    "#     cdef np.uint32_t pathElems = 0\n",
    "\n",
    "#     while curRow > 0:\n",
    "#         if accumCost[curRow, curCol] == MAX_FLOAT:\n",
    "#             print('A path is not possible')\n",
    "#             break\n",
    "\n",
    "#         jump = steps[curRow, curCol]\n",
    "#         if jump < 0: # skip\n",
    "#             curCol = curCol - 1\n",
    "#         else: # jump\n",
    "#             path[pathElems] = curCol\n",
    "#             pathElems = pathElems + 1\n",
    "#             curRow = curRow - 1\n",
    "#             curCol = jump\n",
    "\n",
    "#     return path[::-1]\n",
    "\n",
    "# @cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "# def calc_Tseg(np.ndarray[DTYPE_FLOAT_t, ndim=2] accumCost, np.ndarray[np.uint32_t, ndim=2] stepsForCost, parameter):\n",
    "#     '''\n",
    "\n",
    "#     Parameter should have: 'dn', 'dm'\n",
    "#     '''\n",
    "\n",
    "#     cdef np.ndarray[unsigned int, ndim=1] dn\n",
    "#     cdef np.ndarray[unsigned int, ndim=1] dm\n",
    "#     cdef np.uint32_t numRows = accumCost.shape[0]\n",
    "#     cdef np.uint32_t numCols = accumCost.shape[1]\n",
    "#     cdef np.ndarray[np.int32_t, ndim=1] startLocs = np.zeros(numCols, dtype=np.int32)\n",
    "#     cdef np.uint32_t endCol\n",
    "#     cdef np.uint32_t curRow\n",
    "#     cdef np.uint32_t curCol\n",
    "#     cdef np.uint32_t curStepIndex\n",
    "\n",
    "#     # get step transitions\n",
    "#     if ('dn'  in parameter.keys()):\n",
    "#         dn = parameter['dn']\n",
    "#     else:\n",
    "#         dn = np.array([1, 1, 0], dtype=DTYPE_INT32)\n",
    "#     if 'dm'  in parameter.keys():\n",
    "#         dm = parameter['dm']\n",
    "#     else:\n",
    "#         dm = np.array([1, 0, 1], dtype=DTYPE_INT32)\n",
    "\n",
    "#     # backtrace from every location\n",
    "#     for endCol in range(numCols):\n",
    "#         curCol = endCol\n",
    "#         curRow = numRows - 1\n",
    "#         while curRow > 0:\n",
    "#             if accumCost[curRow, curCol] == MAX_FLOAT: # no valid path\n",
    "#                 startLocs[curCol] = -1\n",
    "#                 break\n",
    "\n",
    "#             curStepIndex = stepsForCost[curRow, curCol]\n",
    "#             curRow = curRow - dn[curStepIndex]\n",
    "#             curCol = curCol - dm[curStepIndex]\n",
    "#             if curRow == 0:\n",
    "#                 startLocs[endCol] = curCol\n",
    "                \n",
    "#     return startLocs\n",
    "\n",
    "# class bcolors:\n",
    "#     HEADER = '\\033[95m'\n",
    "#     OKBLUE = '\\033[94m'\n",
    "#     OKGREEN = '\\033[92m'\n",
    "#     WARNING = '\\033[93m'\n",
    "#     FAIL = '\\033[91m'\n",
    "#     ENDC = '\\033[0m'\n",
    "#     BOLD = '\\033[1m'\n",
    "#     UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alignSSDTW(featfile1, featfile2, steps, weights, downsample, numSegments, outfile = None, profile = False):\n",
    "    \n",
    "#     # compute cost matrix\n",
    "#     F1 = np.load(featfile1) # 12 x N\n",
    "#     F2 = np.load(featfile2) # 12 x M\n",
    "#     swap = (F1.shape[1] > F2.shape[1])\n",
    "#     if swap:\n",
    "#         F1, F2 = F2, F1 # make the shorter sequence the query\n",
    "#     if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "#         if outfile:\n",
    "#             pickle.dump(None, open(outfile, 'wb'))\n",
    "#         return None\n",
    "#     times = []\n",
    "#     times.append(time.time())\n",
    "#     C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "#     times.append(time.time())\n",
    "    \n",
    "#     # run subseqDTW on chunks\n",
    "#     seglen = int(np.ceil(F1.shape[1] / numSegments))\n",
    "#     dn = steps[:,0].astype(np.uint32)\n",
    "#     dm = steps[:,1].astype(np.uint32)\n",
    "#     dw = weights\n",
    "#     params1 = {'dn': dn, 'dm': dm, 'dw': dw, 'SubSequence': True}\n",
    "#     Dparts = []\n",
    "#     Bparts = []\n",
    "#     for i in range(numSegments):\n",
    "#         Cpart = C[i*seglen : min((i+1)*seglen, F1.shape[1]), :]\n",
    "#         [D, B] = DTW_Cost_To_AccumCostAndSteps(Cpart, params1)\n",
    "#         Dparts.append(D)\n",
    "#         Bparts.append(B)\n",
    "#     times.append(time.time())\n",
    "    \n",
    "#     # construct Cseg, Tseg\n",
    "#     Cseg = np.zeros((numSegments, F2.shape[1]))\n",
    "#     Tseg = np.zeros((numSegments, F2.shape[1]), dtype=np.int32)\n",
    "#     for i, Dpart in enumerate(Dparts):\n",
    "#         Cseg[i,:] = Dpart[-1,:]\n",
    "#         Tseg[i,:] = calc_Tseg(Dpart, Bparts[i], params1)\n",
    "#     times.append(time.time())\n",
    "    \n",
    "#     # segment-level DP\n",
    "#     [Dseg, Bseg] = Segment_DP(Cseg, Tseg)\n",
    "#     times.append(time.time())\n",
    "#     segmentEndIdxs = Segment_Backtrace(Dseg, Bseg)\n",
    "#     times.append(time.time())\n",
    "    \n",
    "#     # backtrace on chunks\n",
    "#     wps = []\n",
    "#     for i, endidx in enumerate(segmentEndIdxs):\n",
    "#         params2 = {'dn': dn, 'dm': dm, 'dw': dw, 'SubSequence': True, 'startCol': endidx}\n",
    "#         [wpchunk, _, _] = DTW_GetPath(Dparts[i], Bparts[i], params2)\n",
    "#         wpchunk[0,:] = wpchunk[0,:] + i*seglen  # account for relative offset\n",
    "#         wps.append(wpchunk.copy())\n",
    "#     wp_merged = np.hstack(wps)\n",
    "#     times.append(time.time())\n",
    "    \n",
    "#     if swap:\n",
    "#         wp_merged = np.flipud(wp_merged) # undo swap\n",
    "    \n",
    "#     if outfile:\n",
    "#         pickle.dump(wp_merged, open(outfile, 'wb'))\n",
    "    \n",
    "#     if profile:\n",
    "#         return wp_merged, np.diff(times)\n",
    "#     else:\n",
    "#         return wp_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align a single pair of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featfile1 = 'features/clean/Chopin_Op017No4/Chopin_Op017No4_Afanassiev-2001_pid9130-01.npy'\n",
    "# featfile2 = 'features/clean/Chopin_Op017No4/Chopin_Op017No4_Ben-Or-1989_pid9161-12.npy'\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# downsample = 1\n",
    "# numSegments = 5\n",
    "# wp = alignSSDTW(featfile1, featfile2, steps, weights, downsample, numSegments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align all pairs of audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_list = 'cfg_files/query.test.list'\n",
    "# featdir1 = Path('features/clean')\n",
    "# featdir2 = Path('features/clean') # in case you want to align clean vs noisy\n",
    "# n_cores = 1\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# downsample = 1\n",
    "# segmentVals = [2, 4, 8, 16, 32]\n",
    "# for numSegments in segmentVals:\n",
    "#     outdir = Path(f'experiments_test/ssdtw_{numSegments}_clean')\n",
    "#     alignSegmentalDTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, numSegments, alignSSDTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure runtime of different DTW variants on cost matrices of varying sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRandomFeatureMatrices(sizes, outdir):\n",
    "    \n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    for sz in sizes:\n",
    "        F = np.random.rand(12, sz)\n",
    "        outfile = outdir + f'/F_{sz}.npy'\n",
    "        np.save(outfile, F)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [1000, 2000, 5000, 10000, 20000, 50000]\n",
    "rand_feat_dir = 'features/random'\n",
    "saveRandomFeatureMatrices(sizes, rand_feat_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW\n",
    "outfile = 'dtw_prof.pkl'\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "sizes = [50000, 20000, 10000, 5000, 2000, 1000]\n",
    "N = 10\n",
    "durs = np.zeros((len(sizes), N, 3)) # DTW runtime is broken into 3 parts\n",
    "for i in range(len(sizes)):\n",
    "    sz = sizes[i]\n",
    "    print(f'Running size = {sz} ', end='')\n",
    "    featfile = rand_feat_dir + f'/F_{sz}.npy'\n",
    "    for j in range(N):\n",
    "        print('.', end='')\n",
    "        gc.collect()\n",
    "        _, times = alignDTW(featfile, featfile, steps, weights, downsample, profile=True)\n",
    "        durs[i,j,:] = np.array(times)\n",
    "    print('')\n",
    "pickle.dump([durs, sizes], open(outfile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling WSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WSDTW\n",
    "# outfile = 'wsdtw_prof.pkl'\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# downsample = 1\n",
    "# segmentVals = [2, 4, 8, 16, 32]\n",
    "# sizes = [50000, 20000, 10000, 5000, 2000, 1000]\n",
    "# N = 10\n",
    "# durs = np.zeros((len(segmentVals), len(sizes), N, 5)) # WSDTW runtime is broken into 5 parts\n",
    "# for i, numSegments in enumerate(segmentVals):\n",
    "#     print(f'Running numSegments = {numSegments} ', end='')\n",
    "#     for j, sz in enumerate(sizes):\n",
    "#         print('|', end='')\n",
    "#         featfile = rand_feat_dir + f'/F_{sz}.npy'\n",
    "#         for k in range(N):\n",
    "#             print('.', end='')\n",
    "#             gc.collect()\n",
    "#             _, times = alignWSDTW(featfile, featfile, steps, weights, downsample, numSegments, profile=True)\n",
    "#             durs[i,j,k,:] = np.array(times)\n",
    "#     print('')\n",
    "# pickle.dump([durs, segmentVals, sizes], open(outfile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling SSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SSDTW\n",
    "# outfile = 'ssdtw_prof.pkl'\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# downsample = 1\n",
    "# segmentVals = [2, 4, 8, 16, 32]\n",
    "# sizes = [50000, 20000, 10000, 5000, 2000, 1000]\n",
    "# N = 10\n",
    "# durs = np.zeros((len(segmentVals), len(sizes), N, 6)) # SSDTW runtime is broken into 6 parts\n",
    "# for i, numSegments in enumerate(segmentVals):\n",
    "#     print(f'Running numSegments = {numSegments} ', end='')\n",
    "#     for j, sz in enumerate(sizes):\n",
    "#         print('|', end='')\n",
    "#         featfile = rand_feat_dir + f'/F_{sz}.npy'\n",
    "#         for k in range(N):\n",
    "#             print('.', end='')\n",
    "#             gc.collect()\n",
    "#             _, times = alignSSDTW(featfile, featfile, steps, weights, downsample, numSegments, profile=True)\n",
    "#             durs[i,j,k,:] = np.array(times)\n",
    "#     print('')\n",
    "# pickle.dump([durs, segmentVals, sizes], open(outfile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Alignments on Random Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how closely Segmental DTW variants match DTW alignments on random cost matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRandomFeatureMatrices2(sz, N, outdir):\n",
    "    \n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    for i in range(N):\n",
    "        F = np.random.rand(12, sz)\n",
    "        norm_factor = np.sqrt(np.sum(F*F, axis=0))\n",
    "        F = F / norm_factor\n",
    "        outfile = outdir + f'/F_{sz}_{i}.npy'\n",
    "        np.save(outfile, F)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 10000\n",
    "N = 10\n",
    "rand_feat_dir = 'features/random'\n",
    "saveRandomFeatureMatrices2(sz, N, rand_feat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featfile1 = 'features/random/F_10000_0.npy'\n",
    "featfile2 = 'features/random/F_10000_6.npy'\n",
    "\n",
    "# DTW\n",
    "steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "downsample = 1\n",
    "wp = alignDTW(featfile1, featfile2, steps, weights, downsample)\n",
    "\n",
    "# Segmental DTW variants\n",
    "# steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# weights = np.array([1,1,2])\n",
    "# numSegments = 16\n",
    "# wp2 = alignWSDTW(featfile1, featfile2, steps, weights, downsample, numSegments)\n",
    "# wp3 = alignSSDTW(featfile1, featfile2, steps, weights, downsample, numSegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wp[0,:], wp[1,:], 'k')\n",
    "# plt.plot(wp2[0,:], wp2[1,:], 'r')\n",
    "# plt.plot(wp3[0,:], wp3[1,:], 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DropDTW",
   "language": "python",
   "name": "dropdtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
